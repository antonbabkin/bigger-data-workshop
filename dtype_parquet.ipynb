{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data type optimization and parquet storage\n",
    "\n",
    "- Data types automatically chosen by `pandas.read_csv()` may not always be optimal.\n",
    "  - leading zeros in ZIP codes\n",
    "  - 8 bytes per value where 1 byte would suffice\n",
    "- String columns use up a lot of memory, convert them to categoricals when number of unique values is not too big relative to number of observations.\n",
    "- Parquet storage format preserves dtype information and enables partitioning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data types\n",
    "\n",
    "`pandas` uses NumPy data types internally.\n",
    "\n",
    "### Bits and bytes\n",
    "\n",
    "### Integers\n",
    "\n",
    "### Floats\n",
    "\n",
    "### Missing values\n",
    "\n",
    "### Strings and other objects\n",
    "\n",
    "### Date and time\n",
    "\n",
    "### Categoricals\n",
    "\n",
    "### Experimental nullable dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parquet\n",
    "\n",
    "- Binary data: data type is preserved\n",
    "- Columnar storage: efficient reading of subset of columns and dtype-specific compression\n",
    "- Partitioning: only read chunks that satisfy a given condition\n",
    "  - Every partition adds metadata overhead. With too many partitions, this can incur significant performance cost. For example, if SynIG is partitioned by YEAR, STATE and SECTOR (about 17,000 partitions), it becomes much slower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import fastparquet\n",
    "\n",
    "from tools import ResourceMonitor, state_00_aa\n",
    "from time import sleep\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert SynIG from CSV to parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sectors = ['11', '21', '22', '23', '31', '42', '44', '48', '51', '52',\n",
    "           '53', '54', '55', '56', '61', '62', '71', '72', '81', '92', '99']\n",
    "states = list(state_00_aa.values())\n",
    "\n",
    "def convert_synig_dtypes(df):\n",
    "    if 'STATE' in df:\n",
    "        df['STATE'] = pd.Categorical(df['STATE'], states)\n",
    "    if 'SECTOR' in df:\n",
    "        df['SECTOR'] = pd.Categorical(df['SECTOR'], sectors)\n",
    "    if 'EMPLOYEES_CODE' in df:\n",
    "        df['EMPLOYEES_CODE'] = pd.Categorical(df['EMPLOYEES_CODE'], list('ABCDEFGHIJK'), ordered=True)\n",
    "    for c in ['EMPLOYEES', 'LONGITUDE', 'LATITUDE']:\n",
    "        if c in df:\n",
    "            df[c] = df[c].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "years = range(2001, 2021)\n",
    "years = years[:5]\n",
    "paths = []\n",
    "for year in years:\n",
    "    print(year, end=' ')\n",
    "    df = pd.read_csv(f'data/synig/{year}.csv', dtype=str)\n",
    "    del df['YEAR']\n",
    "    convert_synig_dtypes(df)\n",
    "    path = f'data/synig.pq/YEAR={year}'\n",
    "    fastparquet.write(path, df, file_scheme='hive', write_index=False, partition_on=['STATE'])\n",
    "    paths.append(path)\n",
    "pf = fastparquet.writer.merge(paths)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read one year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mon = ResourceMonitor(interval=0.3)\n",
    "def read_csv():\n",
    "    mon.tag('read csv')\n",
    "    df = pd.read_csv('data/synig/2001.csv', dtype=str)\n",
    "    mon.tag('convert')\n",
    "    convert_synig_dtypes(df)\n",
    "def read_pq():\n",
    "    mon.tag('read pq')\n",
    "    df = pd.read_parquet('data/synig.pq', filters=[('YEAR', '==', 2001)])\n",
    "\n",
    "mon.start()\n",
    "sleep(1)\n",
    "read_csv()\n",
    "sleep(1)\n",
    "read_pq()\n",
    "sleep(1)\n",
    "mon.stop()\n",
    "mon.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read one state\n",
    "\n",
    "Subset of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mon = ResourceMonitor(interval=0.3)\n",
    "years = range(2001, 2021)\n",
    "years = years[:5]\n",
    "state = 'WI'\n",
    "cols = ['YEAR', 'STATE', 'SECTOR', 'EMPLOYEES', 'NAICS']\n",
    "\n",
    "def read_csv():\n",
    "    mon.tag('read csv')\n",
    "    df = []\n",
    "    for year in years:\n",
    "        print(year, end=' ')\n",
    "        d = pd.read_csv(f'data/synig/{year}.csv', dtype=str, usecols=cols)\n",
    "        convert_synig_dtypes(d)\n",
    "        d = d[d['STATE'] == state]\n",
    "        df.append(d)\n",
    "    df = pd.concat(df, ignore_index=True)\n",
    "    print()\n",
    "    print(df.shape)\n",
    "    sleep(1)\n",
    "    \n",
    "def read_pq():\n",
    "    mon.tag('read pq')\n",
    "    df = pd.read_parquet('data/synig.pq', columns=cols, \n",
    "                         filters=[('YEAR', 'in', years), ('STATE', '==', 'WI')])\n",
    "    print(df.shape)\n",
    "    sleep(1)\n",
    "\n",
    "mon.start()\n",
    "sleep(1)\n",
    "read_csv()\n",
    "sleep(1)\n",
    "read_pq()\n",
    "mon.stop()\n",
    "mon.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
