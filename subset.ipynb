{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subsetting and split-apply-combine\n",
    "\n",
    "Subsetting: only load columns and rows that you need.\n",
    "\n",
    "Split-apply-combine strategy:\n",
    "- **split** your data in smaller subsets\n",
    "- **apply** necessary transformation to subsets one at a time, storing transformation results\n",
    "- **combine** results from subsets to get final result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "\n",
    "os.getpid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bigger than memory\n",
    "\n",
    "Loading the whole example dataset in a DataFrame (20M rows, 15 cols) will take about 1 minute and occupy 4GB+ in memory. More memory will be used if you start running computations. Not feasible in Binder environment where memory is limited to 1-2GB, it will crash and restart your kernel. Multiply by 10 for actual InfoGroup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running this cell in Binder will restart your kernel\n",
    "df = []\n",
    "for year in range(2001, 2021):\n",
    "    df.append(pd.read_csv(f'data/synig/{year}.csv'))\n",
    "df = pd.concat(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use a subset for development and testing\n",
    "\n",
    "If data rows are in random order, reading just the first few rows will give you a representative sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "for year in range(2001, 2021):\n",
    "    df.append(pd.read_csv(f'data/synig/{year}.csv', nrows=10_000))\n",
    "df = pd.concat(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('SECTOR')['EMPLOYEES'].agg(['size', 'sum', 'mean']).astype(int).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are not getting all sectors of the economy here. Clearly, row order is not random."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create a random sample\n",
    "\n",
    "Let's create a random 5% sample.\n",
    "\n",
    "I will only use subset of years to save time. Normally you would want to save results of long-running intermediate steps on disk. I will return to this when we talk about `parquet` and `joblib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "for year in range(2001, 2006):\n",
    "    d = pd.read_csv(f'data/synig/{year}.csv')\n",
    "    d = d.sample(frac=0.05)\n",
    "    df.append(d)\n",
    "df = pd.concat(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem with this simple approach on our dataset: longitudinal histories are broken. It won't help if we could even load all years of data and sample from that. Solution: draw random sample of unique identifiers and then get full histories for those identifiers. This approach will yield a sample that has the same distribution as the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abi = []\n",
    "for year in range(2001, 2006):\n",
    "    abi.append(pd.read_csv(f'data/synig/{year}.csv', usecols=['ABI']))\n",
    "abi = pd.concat(abi)\n",
    "abi = abi.drop_duplicates()\n",
    "abi = abi.sample(frac=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "for year in range(2001, 2006):\n",
    "    d = pd.read_csv(f'data/synig/{year}.csv')\n",
    "    d = d.merge(abi, 'left', 'ABI', indicator=True)\n",
    "    d = d[d['_merge'] == 'both']\n",
    "    del d['_merge']\n",
    "    df.append(d)\n",
    "df = pd.concat(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this lightweight sample to get some insights about the whole, for example, compare sector sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('SECTOR')['EMPLOYEES'].agg(['size', 'sum', 'mean']).astype(int).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### persist intermediate data for later use\n",
    "\n",
    "You can save dataframe as CSV, `parquet` (stay tuned) or some other storage format. Or use standard Python `pickle` module. Here I am using `joblib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(df, 'data/rand_5pct.pkl')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restart kernel and import modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = joblib.load('data/rand_5pct.pkl')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### example: size vs age"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
