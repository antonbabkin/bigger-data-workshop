{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Scaling up empirical research to bigger data with Python\n",
    "\n",
    "**Anton Babkin**  \n",
    "Assistant Research Professor  \n",
    "Department of Agricultural and Resource Economics  \n",
    "University of Connecticut  \n",
    "anton.babkin@uconn.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Setup\n",
    "\n",
    "- If you have not already, launch Binder or start Jupyter locally\n",
    "- Run code in setup notebook to test environment and get data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction\n",
    "\n",
    "- Why not **big** data?\n",
    "- What can you do to analyze data that does not fit in memory?\n",
    "  - Assuming that you use Python\n",
    "- I've used methods shown here to work with ~100GB of CSV files, but they scale up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# General advice\n",
    "\n",
    "- Tools presented here will add complexity to your code. Do not use them unless you have to. *Premature optimization is the root of all evil* (Donald Knuth)\n",
    "- Make a small version of your data to develop and debug your code\n",
    "- Use functions to modularize your code and let data be released from memory\n",
    "- Use tests and assertions to verify correctness\n",
    "- Learn to navigate diverse Python ecosystem of open source libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Get bigger machine: university clusters, rent a cloud..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Overview\n",
    "\n",
    "- Measuring resource usage\n",
    "- Chunking, sampling, subsetting and split-apply-combine\n",
    "- Data type optimization\n",
    "- Using parquet for storage\n",
    "- Parallelization\n",
    "- Dask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Measuring resource usage\n",
    "\n",
    "- CPU, memory, disk and network I/O\n",
    "- Task Manager on Windows, Activity Monitor on Mac, `top` on Unix\n",
    "- Every running program is a process (PID)\n",
    "  - and it's subprocesses\n",
    "- Processes request memory from OS to store data (variables) and use CPU time to process them\n",
    "- Under Jupyter, every notebook starts a kernel - Python subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Running time\n",
    "- `DataFrame.memory_usage()`\n",
    "- Total usage by the process: `psutil`\n",
    "- Advanced tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data\n",
    "\n",
    "- InfoGroup: propriatary dataset convering all US businesses since 1997\n",
    "  - about 60 columns and 10M rows per year\n",
    "- SynIG: synthetic random data that looks like InfoGroup\n",
    "  - 20 years, 1M rows per year\n",
    "  - location, industry and employment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Longitudinal (panel) data\n",
    "\n",
    "Table: hypothetical employment\n",
    "\n",
    "| ABI | 2001 | 2002 | 2003 | 2004 | 2005 | 2006 | ... |\n",
    "|-----|------|------|------|------|------|------|-----|\n",
    "| 001 | 1    | 5    | 2    | .    | .    | .    |     |\n",
    "| 002 | 1    | 2    | 2    | 10   | 6    | .    |     |\n",
    "| 003 | .    | 3    | 6    | 5    | 7    | 8    |     |\n",
    "| ... |      |      |      |      |      |      |     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "show CSV tables\n",
    "\n",
    "[NAICS sectors](https://www.census.gov/cgi-bin/sssd/naics/naicsrch?chart=2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Subsetting and split-apply-combine\n",
    "\n",
    "- Subset of rows and columns\n",
    "- Read in chunks\n",
    "- Split in subset, apply transformation to each subset, combine final result\n",
    "- Memory-speed and memory-complexity trade-offs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Examples\n",
    "\n",
    "- Representative random sample\n",
    "- Establishments and employment by sector and year\n",
    "- Size vs age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<script>\n",
    "    document.querySelector('head').innerHTML += '<style>body {font-size: 200%}</style>';\n",
    "</script>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
